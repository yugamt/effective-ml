{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Testing in ML\n",
        "> A demo on Testing in Machine Learning\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [jupyter]\n"
      ],
      "metadata": {
        "id": "iFdgvQEHubZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Should We Test?\n",
        "\n",
        "- Easy to add new features\n",
        "- To avoid a wasted training job.\n",
        "- Better to find shortcomings on your own than from the clients."
      ],
      "metadata": {
        "id": "bQgUT5byu9JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What to Test?\n",
        "\n",
        "1. Pre-train Tests<br />\n",
        "<space><space><space><space>a. Testing the code and the data <br />\n",
        "b. Similar to software testing and the same principles can be used.\n",
        "\n",
        "2. Post-train Tests<br />\n",
        "<space><space><space><space>a. Testing the model (testing model’s skills)<br />\n",
        "b. Well tested code and data are not sufficient to ensure the creation of a good model.<br />\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; i. Evaluation of validation set<br />\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;ii. Testing the model for some expected behaviour.<br />\n",
        "c. These tests contain a set of inputs on which model’s performance is calculated."
      ],
      "metadata": {
        "id": "ZIxLU5dbu9ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-train Tests\n",
        "\n",
        "- Testing the code and the data\n",
        "- Similar to software testing and the same principles can be used.\n",
        "- Types:\n",
        "    \n",
        "    a. Unit tests:\n",
        "    - To test small components of the code and the data.\n",
        "    - Any new function/class added, should have unit test testing it’s functionality.  \n",
        "\n",
        "  b. Regression tests:\n",
        "    - To test bugs which have been encountered before and fixed.\n",
        "    - Can be added as a new unit test.\n",
        "  \n",
        "  c. Integration tests:\n",
        "    - To test execution of multiple small components of the code.\n",
        "    - (find this out)"
      ],
      "metadata": {
        "id": "uHlEiXepvDKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit Tests in ML\n",
        "- Data\n",
        "    - Check for Nan values at unexpected places.\n",
        "    - Check for leakage in your splits (by intersection).\n",
        "    - Check if features values are in the expected range. Similarly for categories.\n",
        "- DataLoader\n",
        "    - Check sample’s shapes (correct or not)\n",
        "    - Check data loading (possible or not)\n",
        "    - Check augmentations (applied or not, shapes)\n",
        "    - Check everything separately for train and test samples.\n",
        "    - Ex: Augmentations differ for train and test.\n",
        "- Model\n",
        "    - Check output shapes, forward pass.\n",
        "    - Check cpu to gpu to cpu transfer.\n",
        "    - Check sample independence.\n",
        "    - Check gradient’s existence for all the expected parameters.\n",
        "- Loss\n",
        "    - Check output type, shape.\n",
        "    - Check expected behaviour.\n",
        "- Trainer\n",
        "    - Ensure fitting (by overfitting a single batch)."
      ],
      "metadata": {
        "id": "WZmNnBQVvCsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-train Tests\n",
        "\n",
        "- Model evaluation on validation set\n",
        "\n",
        "    - We usually do this.\n",
        "    - Effective to compare between two models of 70% and 90% accuracy.\n",
        "    - But comparing models of 90% and 91% accuracy gets tricky.\n",
        "    - Better models could have unexpected failure modes such as bad performance on small objects, gender bias, sensitivity to low lighting conditions etc.\n",
        "\n",
        "- Behavioural testing\n",
        "    - Manual error analysis should be done to identify failure modes of the model.\n",
        "    - Tests should be added to quantify these failure modes.\n",
        "    - These tests would be problem, domain and dataset specific.\n",
        "    - Broadly classified into three types\n",
        "        - Invariance test\n",
        "        - Directional expectation test\n",
        "        - Minimum functionality test"
      ],
      "metadata": {
        "id": "f9vSOzSOu-N3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invariance Test\n",
        "\n",
        "#### Apply label preserving perturbations to inputs and expect model predictions to remain the same.\n",
        "\n",
        "- Replace places names in sentiment analysis.\n",
        "    - Examples:\n",
        "        - @AmericanAir thank you we got on a different flight to [ Chicago → Dallas ].\n",
        "        - @VirginAmerica I can’t lose my luggage, moving to [ Brazil → Turkey ] soon, ugh.\n",
        "- Typos in sentiment analysis.\n",
        "    - Examples:\n",
        "        - The flight was great → The flght ws great.\n",
        "        - Why are we getting so lazy → Why are we gettnig so lazy.\n",
        "- Rotating images in object detection.\n",
        "\n",
        "![](images/mobile.png)"
      ],
      "metadata": {
        "id": "qBKXkmzRvFOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directional Expectation Test\n",
        "\n",
        "#### Apply perturbations to the inputs and expect labels to change in a certain way.\n",
        "\n",
        "\n",
        "- Keeping everything else the same, if house built up area is reduced, does the price increase?\n",
        "- Adding a more negative sentence to the end should not make outputs more positive.\n",
        "    - Examples:\n",
        "        - @USAirways your service sucks. → @USAirways your service sucks. You are lame.\n",
        "        - @JetBlue why won't YOU help them? → @JetBlue why won't YOU help them? I dread you.\n",
        "- Replacing lower half of the image, increase the count?"
      ],
      "metadata": {
        "id": "0_0smnkWvGMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimum Functionality Test\n",
        "\n",
        "#### Simple test cases designed to test a specific behaviour.\n",
        "\n",
        "#### Analogous to unit test where we test the model on a small part of the data.\n",
        "\n",
        "#### Failure modes discovered in error analysis can be tested with MFT.\n",
        "\n",
        "\n",
        "-  Examples:\n",
        "    - Testing on short, long sentences separately in sentiment analysis.\n",
        "    - Testing on small, large objects in object detection.\n",
        "    - Testing on each region’s samples separately.\n",
        "    - Testing on simple sentences created with certain template in sentiment analysis:\n",
        "        - Template: “I {negation} {positive verb} the {thing}”.\n",
        "        - Sentences: I can’t say I recommend the book, I didn’t love the flight etc.\n",
        "\n",
        "![](images/directional_expectation.png)"
      ],
      "metadata": {
        "id": "tSRKezgOvEGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimum Functionality Test\n",
        "\n",
        "-  Examples:\n",
        "    - In pest management’s trap based solution, one of the failure modes is accepting ‘white printed paper’ as a valid trap image.\n",
        "\n",
        "#### Trap Images^ Non-Trap Images^ Test case designed with failure mode images^\n",
        "\n",
        "![](images/min_functionality.png)"
      ],
      "metadata": {
        "id": "loMhZu2WycaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "- Pre-train test\n",
        "    - Unit test\n",
        "    - Regression test\n",
        "    - Integration test\n",
        "\n",
        "- Post-train test\n",
        "- Model evaluation on validation set\n",
        "- Behavioural testing\n",
        "    - Invariance test\n",
        "    - Directional expectation test\n",
        "    - Minimum functionality test"
      ],
      "metadata": {
        "id": "KoFBJGkHyvEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Final ML Pipeline\n",
        "![](images/final_ml.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cin2B7qKuWdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## References\n",
        "\n",
        "- Must read\n",
        "    - How to Trust Your Deep Learning Code (Writing Unit Tests)\n",
        "    - Paper on Testing in NLP\n",
        "\n",
        "- Nice to read\n",
        "    - Testing for ML Systems\n",
        "    - How to Test ML Models"
      ],
      "metadata": {
        "id": "EnOkVswdyyQH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "613TBRhYyy9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}